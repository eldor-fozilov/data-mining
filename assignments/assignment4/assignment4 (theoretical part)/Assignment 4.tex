\documentclass{homework}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\title{IE30301-Datamining Assignment 4 (70 Points)}
\author{Prof. Junghye Lee}
\date{April 29, 2021}


\begin{document}
    \maketitle
    \exercise*
    Summarize the following concepts in $3\sim4$ sentences each. (write it in your own words). If not, there are 2 points deduction per problem. [12 pts, 3 pts for each.]  \\
    \begin{enumerate}
        \item \textbf{Linear Discriminant Analysis}
        \item \textbf{Cross Validation}
        \item \textbf{AUC for ROC curves}
        \item \textbf{Decision Tree}
    \end{enumerate}
    \vspace{10mm}
    
    \exercise*
	Consider a multinomial logistic regression model with the dependent variable that has three or more nominal type categories. If we define $v_{ij}$ as the value of category $j$ from the $r_i$ independent trial 
	\Big(instead of the usual binary logistic regression formula  
	$v_{ij}$ =
	$\begin{cases}
    1, & \text{for } y_{i}=j\\
    0, & \text{for } y_{i} \neq j
    \end{cases}$
	\Big) then the $v_{ij}$  follows a multinomial distribution with probabilities $(P_1,…,P_j)$.\\
	Construct the likelihood function for this case. (It is not that complicated. You just need to use the probability mass function of the multinomial distribution)  [10 pts]
	\vspace{10mm}
	

    \newpage
    
    \exercise*
    Compute the Linear Discriminant projection for the following two-dimensional dataset. [10 pts]
    \begin{table}[!h]
    \begin{center}
    \begin{tabular}{|c|c|c|}
    \hline
    Variable\_A & Variable\_B & Result \\ \hline
    1.84        & 7.57        & 1      \\ \hline
    1.37        & 9.83        & 1      \\ \hline
    2.26        & 7.82        & 1      \\ \hline
    2.18        & 8.71        & 1      \\ \hline
    1.58        & 4.97        & 0      \\ \hline
    1.16        & 6.31        & 0      \\ \hline
    2.27        & 4.32        & 0      \\ \hline
    \end{tabular}
    \end{center}
    \end{table}
    
    \subsection{}
    Calculate the class statistics: scatter matrices $\mathbf{S}$ and mean $\mathbf{\mu}$ ($\mathbf{S}_{1}, \mathbf{S}_{2}, \mathbf{\mu}_{1}, \mathbf{\mu}_{2}$) [4 pts]
    
    \subsection{}
    Calculate the within- and between-class scatter ($\mathbf{S}_{B},\mathbf{S}_{W}$) [3 pts]
    
    \subsection{}
    Based on the results 3.1 and 3.2, calculate the optimal $\mathbf{w}^{\star}$. [3 pts]
    \vspace{10mm}
    
    \exercise*
    The following tables are confusion matrices of the test dataset from the two methods. \\ 
    (Logistic Regression and Decision Tree). [12 pts]
    \begin{table}[!h]
    \begin{center}
    \caption{Logistic Regression}
    \begin{tabular}{|ll|ll|}
    \hline
                                & Predicted             & \multirow{Disorder} & \multirow{No Disorder} \\
    \multicolumn{1}{|c}{Actual} & \multicolumn{1}{c|}{} &                           &                              \\ \hline
    \multicolumn{2}{|l|}{Disorder}                      & \multicolumn{1}{c}{8}     & \multicolumn{1}{c|}{18}      \\
    \multicolumn{2}{|l|}{No Disorder}                   & \multicolumn{1}{c}{45}    & \multicolumn{1}{c|}{929}     \\ \hline
    \end{tabular}
    \end{center}
    \end{table}
    
    \begin{table}[!h]
    \begin{center}
    \caption{Decision Tree}
    \begin{tabular}{|ll|ll|}
    \hline
                                & Predicted             & \multirow{Disorder} & \multirow{No Disorder} \\
    \multicolumn{1}{|c}{Actual} & \multicolumn{1}{c|}{} &                           &                              \\ \hline
    \multicolumn{2}{|l|}{Disorder}                      & \multicolumn{1}{c}{12}    & \multicolumn{1}{c|}{14}      \\
    \multicolumn{2}{|l|}{No Disorder}                   & \multicolumn{1}{c}{60}    & \multicolumn{1}{c|}{914}     \\ \hline
    \end{tabular}
    \end{center}
    \end{table}
    \newpage
    
    \subsection{}
    Explain how we can interpret the accuracy, sensitivity, and specificity, respectively. \\
    Calculate accuracy rate, sensitivity, and specificity for each method. (Positive class = ‘Disorder') [3 pts]
    
    \subsection{}
    Compare the accuracy obtained in (4.1) with that of the naïve rule. \\
    (naïve rule: classify all records as belonging to the most prevalent class) [3 pts]

    \subsection{}
    Which method do you prefer for further implementation in terms of accuracy, sensitivity, and specificity? Explain your reasons. (You should note that the class is imbalanced.) [3 pts]
    
    \subsection{}
    If the accuracy rates of those data mining methods were no better than the naïve rule, what would you do to improve accuracy? (Write your own opinion.) [3 pts]
    
    \vspace{10mm}

    \exercise*
    The following are training samples of 12 objects. Each object is represented as variable X and divided into two classes. (Positive : Class 1, Negative : Class 0) [11 pts]
    
    \begin{table}[!h]
    \begin{center}
    \begin{tabular}{|c|cccccccccccc|}
    \hline
    Object & 1  & 2  & 3  & 4  & 5  & 6  & 7  & 8  & 9  & 10 & 11 & 12 \\ \hline
    X      & 24 & 30 & 35 & 37 & 42 & 49 & 54 & 56 & 60 & 68 & 72 & 73 \\
    Class  & 0  & 0  & 0  & 0 &  1  & 0  & 1  & 1  & 0  & 1  & 1  & 1  \\ \hline
    \end{tabular}
    \end{center}
    \end{table}
  
    \subsection{}
    For the data above, compute sensitivity and specificity according to the change of classification criterion(C) value.\\
    - You should fill in the table below \\
    - Use a classification criterion that if X < C, then classify it as class 0. [6 pts]

    \begin{table}[!h]
    \begin{center}
    \begin{tabular}{|c|c|c|}
    \hline
    Classification criterion & Sensitivity & 1-Specificity \\ \hline
    X < 24                     & 1           & 1           \\ \hline
                             &             &               \\ \hline
                             &             &               \\ \hline
                             &             &               \\ \hline
                             &             &               \\ \hline
                             &             &               \\ \hline
                             &             &               \\ \hline
                             &             &               \\ \hline
                             &             &               \\ \hline
                             &             &               \\ \hline
                             &             &               \\ \hline
                             &             &               \\ \hline                         
    \end{tabular}
    \end{center}
    \end{table}
    
    \newpage
    
    \subsection{}
    Generate ROC curve based on the computed sensitivity and specificity. And explain how to interpret the ROC curve.
    [5 pts] \\
    (Use Python or R to plot the ROC curve, 
    but you should provide a screenshot of the code for generating the plot)
    
    \newpage    
    
    \exercise*
    The following data set was collected from the survey, consisting of four attributes: Age, Health Concern, Exercise, Health Status, and one target variable: Health Checkup. [15 pts]
    \textbf{(For only exercise 6, Handwriting is allowed. Illegible handwriting will not be graded)}
    
    \begin{table}[!h]
    \begin{center}
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{Age} & \multicolumn{1}{l|}{\textbf{Health Concern}} & \multicolumn{1}{l|}{\textbf{Exercise}} & \multicolumn{1}{l|}{\textbf{Health Status}} & \multicolumn{1}{l|}{\textbf{Health Checkup}} \\ \hline
    senior       & low                                          & frequent                               & fair                                        & yes                                          \\ \hline
    middle-aged  & high                                         & seldom                                 & fair                                        & yes                                          \\ \hline
    youth        & medium                                       & frequent                               & excellent                                   & yes                                          \\ \hline
    middle-aged  & medium                                       & seldom                                 & excellent                                   & yes                                          \\ \hline
    youth        & high                                         & seldom                                 & excellent                                   & no                                           \\ \hline
    youth        & medium                                       & seldom                                 & fair                                        & no                                           \\ \hline
    middle-aged  & low                                          & frequent                               & excellent                                   & yes                                          \\ \hline
    middle-aged  & high                                         & frequent                               & fair                                        & yes                                          \\ \hline
    senior       & medium                                       & seldom                                 & excellent                                   & no                                           \\ \hline
    youth        & high                                         & seldom                                 & fair                                        & no                                           \\ \hline
    senior       & low                                          & frequent                               & excellent                                   & no                                           \\ \hline
    senior       & medium                                       & seldom                                 & fair                                        & yes                                          \\ \hline
    youth        & low                                          & frequent                               & fair                                        & yes                                          \\ \hline
    senior       & medium                                       & frequent                               & fair                                        & yes                                          \\ \hline
    \end{tabular}
    \end{center}
    \end{table}
    
    \subsection{}
    Compute the Gain Ratio for each attribute. Which variable will be a splitting criterion at the root node in terms of Gain Ratio? (Take the multi-split approach for splitting and the binary logarithm (i.e., base 2) for calculating the Gain Ratio. Write down the calculation process) [10 pts]
    
    \subsection{}
    What is the classification error right after splitting the root node according to the result of 5.1? [5 pts]

 
        
     
  
\end{document}
