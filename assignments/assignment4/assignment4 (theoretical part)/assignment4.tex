\documentclass{homework}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\title{IE30301-Data Mining Assignment 4 (70 Points)}
\author{Eldor Fozilov}
\date{April 13, 2022}


\begin{document}
    \maketitle
    \exercise*
    Summarize the following concepts in $3\sim4$ sentences each. (write it in your own words). If not, there are 2 points deduction per problem. [12 pts, 3 pts for each.]  \\
    \begin{enumerate}
        \item \textbf{Linear Discriminant Analysis} is a machine learning method designed to solve classification problems by performing dimensionality reduction, considering the label information. It aims at optimally projecting data points into a subspace so that those data points belonging to different classes end up being separated from each other after the projection. The dimension of that subspace depends on the number of classes: if there are \textbf{C} classes, then the data (excluding the target variable) will be reduced to \textbf{C-1} dimensional subspace. After the optimal subspace is determined, new records will be projected to that subspace and they will be assigned to a particular class which represents the closest projected sample records in the train data set to that new record.  
        
        \item \textbf{Cross Validation} is a way of evaluating the performance of machine learning models. It offers a particular method to estimate model performance on unseen data not used while training. Firstly, data is split into \textbf{k} subsets (k is defined by the user) of equal size, and then each subset in turn is used for testing and the remainder for training. To determine the overall error rate, the error estimates are averaged across all iterations. Cross validation is very useful when the size of a given data set is small, in which case splitting the data set into training, validation, and testing set might negatively affect accuracy of a model.
        
        \item \textbf{AUC for ROC curves} is an evaluation metric for checking performance of a classification model. The graphic example of a ROC curve is provided below. As we can see, ROC curve plots TRP (true positive rate) vs. FPR (false positive rate) at different classification probability thresholds. Decreasing the probability threshold classifies more items as positive, which increases both TPR and FPR. What \textbf{AUC} measures is the area underneath the ROC curve, which represent an aggregate measure of performance across all possible classification thresholds (from 0 to 1). So, that is why we want AUC to be as high as possible. The range of values AUC can take is from 0 to 1, and a model whose predictions are all wrong has an AUC measure of 0; one whose predictions are all correct has an AUC measure of 1. The AUC benchmark for the performance of a model is 0.5, which represents the performance of a strategy in which classification predictions are made randomly.
        
        \begin{center}
        \includegraphics[width=0.5\textwidth, scale = 0.5]{AUC.png}
        \end{center}
        
        \item \textbf{Decision Tree} is a supervised-machine learning method used for both classification and regression. What makes this method different from other machine learning methods is that it is a rule-based model: the constructed decision tree provides a set of rules, which determine how sample records are classified or what the regression prediction ends up being for those sample records. To determine the set of rules, we first decide how to split the records into branches on each level in our decision tree. For doing this, \textbf{multi-way split} or \textbf{binary split} methods are used when dealing with nominal variables; \textbf{discretization} and \textbf{binary decision} methods are used when dealing with continuous variable). Then, for classification, optimization criteria such as $\mathbf{GainRATIO_{split}}$ and for regression, optimization criterion focused on \textbf{MSE} or \textbf{variance} of the target variable are employed to select a feature that results in the most optimal split. 
        
        
        
        
        
    \end{enumerate}
    \vspace{3mm}
    
    \exercise*
	Consider a multinomial logistic regression model with the dependent variable that has three or more nominal type categories. If we define $v_{ij}$ as the value of category $j$ from the $r_i$ independent trial 
	\Big(instead of the usual binary logistic regression formula  
	$v_{ij}$ =
	$\begin{cases}
    1, & \text{for } y_{i}=j\\
    0, & \text{for } y_{i} \neq j
    \end{cases}$
	\Big) then the $v_{ij}$  follows a multinomial distribution with probabilities $(P_1,…,P_j)$.\\
	Construct the likelihood function for this case. (It is not that complicated. You just need to use the probability mass function of the multinomial distribution)  [10 pts]
	
	\textbf{\textcolor{red}{Answer}}: \\
	Let's assume we have \textbf{n} independent trials and \textbf{C} number of categories, where $\mathbf{C} \ge 3$. 
	Let's also say that the random variable $V_i$ represent the value of an observed category in the i-th independent trial. \\
	Then,
	\begin{equation*}
	    P(V_i = v_{ij}) = \prod_{j = 1}^{C} P_j^{a_{ij}}, \quad \text{where}\  a_{ij} =
	    \begin{cases}
    1, & \text{for } V_{i}=v_{ij}\\
    0, & \text{for } V_{i} \neq v_{ij}
    \end{cases}
	\end{equation*}
    Now, we can write the likelihood function in the following way:
    \begin{equation*}
    \begin{gathered}
        L = \prod_{i=1}^n \dfrac{n!}{n_1! \cdot n_2! \cdot...\cdot n_C!} \prod_{j=1}^C [P(V_i = v_{ij})]^{n_j} = \prod_{i=1}^n \dfrac{n!}{n_1! \cdot n_2! \cdot...\cdot n_C!} \prod_{j=1}^C P_j^{n_j},
    \end{gathered}
    \end{equation*}
    where $n_j$ (j = 1,2,...,C) represents the number of trials that fall in category j out of n trials, and $\sum_{j=1}^C n_j = n$
	\vspace{10mm}

    
    \exercise*
    Compute the Linear Discriminant projection for the following two-dimensional dataset. [10 pts]
    \begin{table}[!h]
    \begin{center}
    \begin{tabular}{|c|c|c|}
    \hline
    Variable\_A & Variable\_B & Result \\ \hline
    1.84        & 7.57        & 1      \\ \hline
    1.37        & 9.83        & 1      \\ \hline
    2.26        & 7.82        & 1      \\ \hline
    2.18        & 8.71        & 1      \\ \hline
    1.58        & 4.97        & 0      \\ \hline
    1.16        & 6.31        & 0      \\ \hline
    2.27        & 4.32        & 0      \\ \hline
    \end{tabular}
    \end{center}
    \end{table}
    
    \subsection{}
    Calculate the class statistics: scatter matrices $\mathbf{S}$ and mean $\mathbf{\mu}$ ($\mathbf{S}_{1}, \mathbf{S}_{2}, \mathbf{\mu}_{1}, \mathbf{\mu}_{2}$) [4 pts]
    
    \textbf{\textcolor{red}{Answer}}:
    
    We will use the following formula to calculate $\mathbf{S_1}$, related to \textbf{class "0"} and $\mathbf{S_2}$, related to \textbf{class "1"}:
    \[ S_i = \sum_{\mathbf{x}\in w_i} \mathbf{(x - \mu_i)(x-\mu_i)}^T \]
    
    First we will calculate the mean vectors:    
    \begin{equation*}
        \begin{gathered}
        \mathbf{\mu_1} = \dfrac{1}{3}\left(\begin{bmatrix} 1.58 \\ 4.97 \end{bmatrix} + 
        \begin{bmatrix} 1.16 \\ 6.31 \end{bmatrix} +
        \begin{bmatrix} 2.27 \\ 4.32 \end{bmatrix}\right) = \begin{bmatrix}
        1.67 \\ 5.2 \end{bmatrix} \\[5pt] 
        \mathbf{\mu_2} = \dfrac{1}{4}\left(\begin{bmatrix} 1.84 \\ 7.57\end{bmatrix} + \begin{bmatrix}   1.37 \\ 9.83 \end{bmatrix} + 
        \begin{bmatrix}     2.26 \\ 7.82\end{bmatrix} + 
        \begin{bmatrix} 2.18 \\ 8.71\end{bmatrix}
        \right) = \begin{bmatrix} 1.9125 \\ 8.4825\end{bmatrix}
        \end{gathered}
    \end{equation*}
    Then, 
    \begin{equation*}
        \begin{gathered}
        \mathbf{S_1} = \begin{bmatrix}  1.58 - 1.67 \\ 4.97 - 5.2 \end{bmatrix}
        \begin{bmatrix}  1.58 - 1.67 \\ 4.97 - 5.2 \end{bmatrix}^T +
        \begin{bmatrix}  1.16 - 1.67 \\ 6.31 - 5.2 \end{bmatrix}
        \begin{bmatrix}  1.16 - 1.67 \\ 6.31 - 5.2 \end{bmatrix}^T + 
        \begin{bmatrix}  2.27 - 1.67 \\ 4.32 - 5.2 \end{bmatrix}
        \begin{bmatrix}  2.27 - 1.67 \\ 4.32 - 5.2 \end{bmatrix}^T \\[5pt]
        = \begin{bmatrix} -0.09 \\ -0.23\end{bmatrix}
        \begin{bmatrix} -0.09 \\ -0.23\end{bmatrix}^T +
        \begin{bmatrix} -0.51 \\ 1.11\end{bmatrix}
        \begin{bmatrix} -0.51 \\ 1.11\end{bmatrix}^T +
        \begin{bmatrix} 0.6 \\ -0.88\end{bmatrix}
        \begin{bmatrix} 0.6 \\ -0.88\end{bmatrix}^T = 
        \begin{bmatrix}
        0.6282 & -1.0734 \\
        -1.0734 & 2.0594 \\
        \end{bmatrix}
        \\[8pt]
        \mathbf{S_2} = \begin{bmatrix} 1.84 - 1.9125 \\ 7.57 - 8.4825 \end{bmatrix}
        \begin{bmatrix} 1.84 - 1.9125 \\ 7.57 - 8.4825 \end{bmatrix}^T + 
        \begin{bmatrix} 1.37 - 1.9125 \\ 9.83 - 8.4825 \end{bmatrix}
        \begin{bmatrix} 1.37 - 1.9125 \\ 9.83 - 8.4825 \end{bmatrix}^T + \\
        \begin{bmatrix} 2.26 - 1.9125 \\ 7.82 - 8.4825 \end{bmatrix}
        \begin{bmatrix} 2.26 - 1.9125 \\ 7.82 - 8.4825 \end{bmatrix}^T
        + \begin{bmatrix} 2.18 - 1.9125 \\ 8.71 - 8.4825 \end{bmatrix}
        \begin{bmatrix} 2.18 - 1.9125 \\ 8.71 - 8.4825 \end{bmatrix}^T\\[5pt]
        = \begin{bmatrix} 0.4919 & -0.8342 \\ -0.8342 & 3.4391  \end{bmatrix}
        
        \end{gathered}
    \end{equation*}
    
    \subsection{}
    Calculate the within- and between-class scatter ($\mathbf{S}_{B},\mathbf{S}_{W}$) [3 pts]

    \textbf{\textcolor{red}{Answer}}: \\
    \begin{equation*}
    \begin{gathered}
    \mathbf{S_W} = \mathbf{S_1 + S_2} =  \begin{bmatrix}
        0.6282 & -1.0734 \\
        -1.0734 & 2.0594 \\
        \end{bmatrix} + \begin{bmatrix} 0.4919 & -0.8342 \\ -0.8342 & 3.4391  \end{bmatrix} = 
        \begin{bmatrix}
        1.1201 & -1.9076 \\
        -1.9076 & 5.4985 \\
        \end{bmatrix}\\[5pt]
    \mathbf{S_B} = (\mathbf{\mu_1 - \mu_2})(\mathbf{\mu_1 - \mu_2})^T = 
    \begin{bmatrix} 1.67 - 1.9125 \\ 5.2 - 8.4825 \end{bmatrix}
    \begin{bmatrix} 1.67 - 1.9125 \\ 5.2 - 8.4825 \end{bmatrix}^T = 
    \begin{bmatrix}
    0.0588 &  0.796\\
    0.796 & 10.7748 \\
    \end{bmatrix}
    \end{gathered}
    \end{equation*}
    
    \subsection{}
    Based on the results 3.1 and 3.2, calculate the optimal $\mathbf{w}^{\star}$. [3 pts]
    
    \textbf{\textcolor{red}{Answer}}: \\
    \[\mathbf{w}^{\star} = \mathbf{S_W^{-1}}\mathbf{(\mu_1 - \mu_2)} \]
    $\mathbf{S_W^{-1}}$ exists, and it is (approximately) equal to \begin{bmatrix}
    2.182 & 0.757 \\ 0.757 & 0.4445
    \end{bmatrix}
    
    So,
    \begin{equation*}
        \mathbf{w}^{\star} = \begin{bmatrix}
    2.182 & 0.757 \\ 0.757 & 0.4445
    \end{bmatrix}\begin{bmatrix}
    1.67 - 1.9125 \\ 5.2 - 8.4825
    \end{bmatrix} = \begin{bmatrix}
    2.182 & 0.757 \\ 0.757 & 0.4445
    \end{bmatrix}\begin{bmatrix}
    -0.2425 \\ -3.2825
    \end{bmatrix} = \begin{bmatrix}
    -3.014 \\ -1.643 
    \end{bmatrix}
    \end{equation*}
    
    \vspace{10mm}
    
    \exercise*
    The following tables are confusion matrices of the test dataset from the two methods. \\ 
    (Logistic Regression and Decision Tree). [12 pts]
    \begin{table}[!h]
    \begin{center}
    \caption{Logistic Regression}
    \begin{tabular}{|ll|ll|}
    \hline
                                & Predicted             & \multirow{Disorder} & \multirow{No Disorder} \\
    \multicolumn{1}{|c}{Actual} & \multicolumn{1}{c|}{} &                           &                              \\ \hline
    \multicolumn{2}{|l|}{Disorder}                      & \multicolumn{1}{c}{8}     & \multicolumn{1}{c|}{18}      \\
    \multicolumn{2}{|l|}{No Disorder}                   & \multicolumn{1}{c}{45}    & \multicolumn{1}{c|}{929}     \\ \hline
    \end{tabular}
    \end{center}
    \end{table}
    
    \begin{table}[!h]
    \begin{center}
    \caption{Decision Tree}
    \begin{tabular}{|ll|ll|}
    \hline
                                & Predicted             & \multirow{Disorder} & \multirow{No Disorder} \\
    \multicolumn{1}{|c}{Actual} & \multicolumn{1}{c|}{} &                           &                              \\ \hline
    \multicolumn{2}{|l|}{Disorder}                      & \multicolumn{1}{c}{12}    & \multicolumn{1}{c|}{14}      \\
    \multicolumn{2}{|l|}{No Disorder}                   & \multicolumn{1}{c}{60}    & \multicolumn{1}{c|}{914}     \\ \hline
    \end{tabular}
    \end{center}
    \end{table}
    \newpage
    
    \subsection{}
    Explain how we can interpret the accuracy, sensitivity, and specificity, respectively. \\
    Calculate accuracy rate, sensitivity, and specificity for each method. (Positive class = ‘Disorder') [3 pts]
    
    \textbf{\textcolor{red}{Answer}}:
    
    For \textbf{logistic regression}, we have the following: \\[5pt]
    Accuracy rate = $\dfrac{8 + 929}{8+18+45+929} = 0.937$ \\[5pt]
    Sensitivity = $\dfrac{8}{8+18} = 0.308$\\[5pt]
    Specificity = $\dfrac{929}{45+929} = 0.954$\\
    
    For \textbf{decision tree}, we have the following: \\[5pt]
    Accuracy rate = $\dfrac{12+914}{12+14+60+914} = 0.926$\\[5pt]
    Sensitivity = $\dfrac{12}{12+14} = 0.462$\\[5pt]
    Specificity = $\dfrac{914}{60 + 914} = 0.938$
    
    
    
    \subsection{}
    Compare the accuracy obtained in (4.1) with that of the naïve rule. \\
    (naïve rule: classify all records as belonging to the most prevalent class) [3 pts]
    
    \textbf{\textcolor{red}{Answer}}:
    
    \begin{table}[!h]
    \begin{center}
    \caption{Naive method}
    \begin{tabular}{|ll|ll|}
    \hline
                                & Predicted             & \multirow{Disorder} & \multirow{No Disorder} \\
    \multicolumn{1}{|c}{Actual} & \multicolumn{1}{c|}{} &                           &                              \\ \hline
    \multicolumn{2}{|l|}{Disorder}                      & \multicolumn{1}{c}{0}    & \multicolumn{1}{c|}{26}      \\
    \multicolumn{2}{|l|}{No Disorder}                   & \multicolumn{1}{c}{0}    & \multicolumn{1}{c|}{974}     \\ \hline
    \end{tabular}
    \end{center}
    \end{table}
    When \textbf{naive rule} is used, \textbf{accuracy rate} is $\dfrac{974}{26+974} = 0.974$, which is higher than accuracy\\[5pt]
    rates found using \textbf{decision tree} and \textbf{logistic regression} in (4.1).

    \subsection{}
    Which method do you prefer for further implementation in terms of accuracy, sensitivity, and specificity? Explain your reasons. (You should note that the class is imbalanced.) [3 pts]
    
    \textbf{\textcolor{red}{Answer}}:
    
    In the problem that we are dealing with, which is classifying records to either “Disorder” or “No Disorder” class, it is much more important for us to identify records having a disorder correctly rather than identifying records that have no disorder because it is evident that the cost of making a
    mistake, which can be a person's life, in misclassifying a \textbf{disorder record} as a \textbf{no-disorder record} is much higher than the opposite case. So, we want the sensitivity measure to be as high as possible, but we agree to tolerate lower specificity value and overall accuracy rate.
    We will choose \textbf{Decision Tree} method for implementation since it has the highest sensitivity value compared to sensitivity value obtained using logistic regression method and
    naïve rule, which has a sensitivity value of zero.
    
    \subsection{}
    If the accuracy rates of those data mining methods were no better than the naïve rule, what would you do to improve accuracy? (Write your own opinion.) [3 pts]
    
    \textbf{\textcolor{red}{Answer}}:
    
    We saw that naïve rule gave us higher accuracy rate compared to
    logistic regression and decision tree methods. This probably happened because one class, specifically “No Disorder” class, greatly dominated in our data set (974 no-disorder records versus 26 disorder records), and thus logistic regression and decision tree methods struggled to separate classes correctly, showing lower overall accuracy rate.
    
    Thus, in order to increase the accuracy rates of logistic regression and decision tree methods, we
    can oversample rare class (disorder records) and increase the number of disorder records in our dataset. As a result, logistic regression and decision tree methods will have more information
    about the rare class and can better understand the differences between it and the dominant class. As a result, we might end up with improved accuracy rates of those methods.
    
    To improve accuracy, we can also try to use a higher cutoff value than 0.5 to classify records in a more conservative way.
    \vspace{10mm}
    \newpage
    \exercise*
    The following are training samples of 12 objects. Each object is represented as variable X and divided into two classes. (Positive : Class 1, Negative : Class 0) [11 pts]
    
    \begin{table}[!h]
    \begin{center}
    \begin{tabular}{|c|cccccccccccc|}
    \hline
    Object & 1  & 2  & 3  & 4  & 5  & 6  & 7  & 8  & 9  & 10 & 11 & 12 \\ \hline
    X      & 24 & 30 & 35 & 37 & 42 & 49 & 54 & 56 & 60 & 68 & 72 & 73 \\
    Class  & 0  & 0  & 0  & 0 &  1  & 0  & 1  & 1  & 0  & 1  & 1  & 1  \\ \hline
    \end{tabular}
    \end{center}
    \end{table}
  
    \subsection{}
    For the data above, compute sensitivity and specificity according to the change of classification criterion(C) value.\\
    - You should fill in the table below \\
    - Use a classification criterion that if X < C, then classify it as class 0. [6 pts]

    \begin{table}[!h]
    \begin{center}
    \begin{tabular}{|c|c|c|}
    \hline
    Classification criterion & Sensitivity & 1-Specificity \\ \hline
    X < 24                     & 1           & 1           \\ \hline
    X < 30                         & 1            &  0.83     \\ \hline
    X < 35                         & 1            & 0.67              \\ \hline
    X < 37                         & 1            & 0.5              \\ \hline
    X < 42                         & 1            & 0.33              \\ \hline
    X < 49                         &  0.83           & 0.33               \\ \hline
    X < 54                         & 0.83            & 0.17               \\ \hline
    X < 56                         & 0.67            & 0.17               \\ \hline
    X < 60                         &  0.5           & 0.17              \\ \hline
    X < 68                         & 0.5            & 0              \\ \hline
    X < 72                         &  0.33           &    0           \\ \hline
    X < 73                         &  0.17           & 0               \\ \hline                         
    \end{tabular}
    \end{center}
    \end{table}
    \newpage
    \textbf{\textcolor{red}{Answer}}:
    
    \includegraphics[width=\textwidth]{5.1.png}
    
    \newpage
    
    \subsection{}
    Generate ROC curve based on the computed sensitivity and specificity. And explain how to interpret the ROC curve.
    [5 pts] \\
    (Use Python or R to plot the ROC curve, 
    but you should provide a screenshot of the code for generating the plot)
    
    \textbf{\textcolor{red}{Answer}}:\\
    
     \includegraphics[width=\textwidth]{5.2.png}
     
     We know that if the area under the ROC curve is big (higher than the benchmark of 0.5), which is actually the case as we see from the graph above, then the performance of the model can be considered satisfactory.
    
    
    \newpage    
    
    \exercise*
    The following data set was collected from the survey, consisting of four attributes: Age, Health Concern, Exercise, Health Status, and one target variable: Health Checkup. [15 pts]
    \textbf{(For only exercise 6, Handwriting is allowed. Illegible handwriting will not be graded)}
    
    \begin{table}[!h]
    \begin{center}
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{Age} & \multicolumn{1}{l|}{\textbf{Health Concern}} & \multicolumn{1}{l|}{\textbf{Exercise}} & \multicolumn{1}{l|}{\textbf{Health Status}} & \multicolumn{1}{l|}{\textbf{Health Checkup}} \\ \hline
    senior       & low                                          & frequent                               & fair                                        & yes                                          \\ \hline
    middle-aged  & high                                         & seldom                                 & fair                                        & yes                                          \\ \hline
    youth        & medium                                       & frequent                               & excellent                                   & yes                                          \\ \hline
    middle-aged  & medium                                       & seldom                                 & excellent                                   & yes                                          \\ \hline
    youth        & high                                         & seldom                                 & excellent                                   & no                                           \\ \hline
    youth        & medium                                       & seldom                                 & fair                                        & no                                           \\ \hline
    middle-aged  & low                                          & frequent                               & excellent                                   & yes                                          \\ \hline
    middle-aged  & high                                         & frequent                               & fair                                        & yes                                          \\ \hline
    senior       & medium                                       & seldom                                 & excellent                                   & no                                           \\ \hline
    youth        & high                                         & seldom                                 & fair                                        & no                                           \\ \hline
    senior       & low                                          & frequent                               & excellent                                   & no                                           \\ \hline
    senior       & medium                                       & seldom                                 & fair                                        & yes                                          \\ \hline
    youth        & low                                          & frequent                               & fair                                        & yes                                          \\ \hline
    senior       & medium                                       & frequent                               & fair                                        & yes                                          \\ \hline
    \end{tabular}
    \end{center}
    \end{table}
    \vspace{15mm}
    
    \subsection{}
    Compute the Gain Ratio for each attribute. Which variable will be a splitting criterion at the root node in terms of Gain Ratio? (Take the multi-split approach for splitting and the binary logarithm (i.e., base 2) for calculating the Gain Ratio. Write down the calculation process) [10 pts]
    
    \subsection{}
    What is the classification error right after splitting the root node according to the result of 5.1? [5 pts]
    \newpage
    \textbf{\textcolor{red}{Answer}} for \large{\textbf{6.1}} and \large{\textbf{6.2}}:
    
    \includegraphics[width=\textwidth]{6.1.(1).jpg}
    \includegraphics[width=\textwidth]{6.1.(2).jpg}
    \includegraphics[width=\textwidth]{6.1.(3).jpg}
    \includegraphics[width=\textwidth]{6.1-2.jpg}
    
    
        
     
  
\end{document}
