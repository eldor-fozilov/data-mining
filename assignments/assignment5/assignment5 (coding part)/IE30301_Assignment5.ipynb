{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "\n",
    "- It is not allowed for you to use packages other than the specified packages below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load Dataset [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the csv file,'X_dataset.csv' as `X`\n",
    "- Load the csv file, 'y_dataset.csv' as `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Split Dataset into the train & testset [1 point]\n",
    "** When you use scikit-learn method to split the train & test set : \n",
    "- the `random_state` value has to be zero.\n",
    "- the ratio of train set and test set is as follows : 75% train set / 25% test set\n",
    "- Assign the variable names as follows : `X_tn`, `X_te`, `y_tn`, `y_te`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Standardize the dataset by \"StandardScaler\" method of scikit-learn [1 point]\n",
    "- Use the method as the default state\n",
    "- Fit the `StandardScaler` on your training data only, then standardize both training and test sets using that scaler. The reason we fit a scaler on the training set is to avoid possible information leakage from the test dataset. Test dataset should always remain \"Unseen\" until the testing phase. Thus, we should always scale using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Load and train a support vector machine classifier (SVC) by scikit-learn. [10 points]\n",
    "- Use only two parameters of `SVC` : `kernel`, and `random_state`.\n",
    "- Assign `model1` to `SVC` with `kernel` set to `linear`, and set `random_state` as 0.\n",
    "- Assign `model2` to `SVC` with `kernel` set to `rbf`, and set `random_state` as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Predict and evaluate the two models on your test set [3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predict class labels of the test set using the two trained models, including `model1` and `model2`.\n",
    "- For each of the two models, assign `pred1` and `pred2` to each predicted result accordingly, and print `pred1` and `pred2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluate the prediction of your models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate the trained model using accuracy metric on the test set.\n",
    "(Evaluate how well the predicted label of the test set matches the actual correct answer value.)\n",
    "- Print the accuracy score value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Fill in the blank of the accuracy function to calculate accuracy score. [2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the accuracy rate from the predicted target value and the actual target value.\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    y_true: actual target value\n",
    "    y_pred: predicted target value\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    calculataed accuracy rate\n",
    "\n",
    "    \"\"\"\n",
    "    # TODO: Compute the accuracy rate\n",
    "    \n",
    "\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Print each accuracy score for `model1` and `model2`. [2 points]\n",
    "- Assign an `accuracy1` to the accuracy score for `model1`.\n",
    "- Assign an `accuracy2` to the accuracy score for `model2`.\n",
    "- Print both `accuracy1` and `accuracy2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the accuracy score on your test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Plot graphs \n",
    "[overall instruction]\n",
    "- Plot test data points using the `matplotlib.pyplot` library\n",
    "- The meaning of dependent variable is such as: \n",
    "-    1 : positive (breast cancer)\n",
    "-    0 : negative (breast cancer)\n",
    "- For label 1 and label 0, plot those labels by assigning different colors or symbols.\n",
    "- Draw the *decision boundary* per each model.\n",
    "- Refer to the below pictures as examples (There is no need to exactly imitate the image below.)\n",
    "- Recommend to use `plt.scatter` function (You are allowed to use another function as well.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](./example.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1. Plot test data points and draw a decision boundary of `model1`. [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2. Plot test data points and draw a decision boundary of `model2`. [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3. Describe the difference between two plots and explain why the accuracy score of a particular model is better than the other based on the two plots. [3 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gilon",
   "language": "python",
   "name": "gilon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
